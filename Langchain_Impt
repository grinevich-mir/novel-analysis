#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from langchain import LLMChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

api_key = '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'

chat = ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo-16k", max_tokens=15000, openai_api_key=api_key, request_timeout=1000)

template = "You are an expert novel reader. You understand the context of dialogues and recognise the speaker of those dialogues."

system_message_prompt = SystemMessagePromptTemplate.from_template(template)

human_template = "Please extract the diaglogues along with the speaker namee from the following text: \n {chnk}"

human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])

chain = LLMChain(llm=chat, prompt=chat_prompt)

# Define the chunk size and overlap
chunk_size = 5000  # Maximum token limit for GPT-3.5 is 4096

overlap = 500  # Number of tokens for overlapping context

def extract_dialogues_from_chapter(chapter_file):
    with open(chapter_file, 'r') as file:
        chapter_text = file.read()

    # Split the chapter into overlapping chunks
    chunks = []
    start = 0
    end = chunk_size
    while start < len(chapter_text):
        chunks.append(chapter_text[start:end])
        start = end - overlap
        end = start + chunk_size
    
    dialogues = []
    for chunk in chunks:
        response = chain.run(chnk=chunk)
        dialogues.append(response)
        
chapter_file = './Data/Glimpse_Ch1.txt'  # Provide the path to the chapter file

dialogues = extract_dialogues_from_chapter(chapter_file)

#%% Output formating

